{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions to import a trained MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pref_voting.generate_utility_profiles\n",
    "import pref_voting.utility_profiles\n",
    "import pref_voting.utility_functions\n",
    "import pref_voting.voting_methods\n",
    "import pref_voting.profiles\n",
    "import pref_voting.generate_profiles\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import math\n",
    "\n",
    "import pickle\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import glob\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "DEVICE = 'mps'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_permutations(n):\n",
    "    \n",
    "    # create a list from 0 to n-1\n",
    "    num_list = list(range(n))\n",
    "\n",
    "    # generate all permutations\n",
    "    perms = list(itertools.permutations(num_list))\n",
    "\n",
    "    return perms\n",
    "\n",
    "permutations_of = dict()\n",
    "permutations_of = {\n",
    "    i: generate_permutations(i)\n",
    "    for i in range(3, 7)\n",
    "}\n",
    "\n",
    "permutations_index_dict = {\n",
    "    i : {\n",
    "            tuple(permutations_of[i][j]) : j \n",
    "            for j in range(len(permutations_of[i]))\n",
    "        }\n",
    "    for i in range(3, 7)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_linear_prof(uprof):\n",
    "    \"\"\"Convert a utility profile to a profile of linear orders.\"\"\" \n",
    "    return pref_voting.profiles.Profile([sorted(uprof.domain, key=lambda x: u(x), reverse=True) for u in uprof.utilities])\n",
    "\n",
    "def clone_voter(prof, manip_weight = 1): \n",
    "    \"\"\"\n",
    "    Clone the first voter so that there are an additional manip_weight - 1 copies of the first voter.  Return the profile with the clones of the voter. \n",
    "    \"\"\"\n",
    "    rankings, rcounts = prof.rankings_counts\n",
    "    rcounts = list(rcounts)\n",
    "    rankings = list([tuple(r) for r in rankings])\n",
    "    new_rcounts = [rcounts[0] + (manip_weight - 1)] + rcounts[1:]\n",
    "    return pref_voting.profiles.Profile(rankings, rcounts=new_rcounts)\n",
    "\n",
    "def apply_manipulation(prof_with_clones, new_ranking, manip_weight):\n",
    "    \"\"\"\n",
    "    Given a profile (with clones), replace manip_weight copies of voter 1's ranking with new_ranking.   It is assumed that prof_with_clones has manip_weight copies of voter 0. \n",
    "    \"\"\"\n",
    "    return pref_voting.profiles.Profile([new_ranking] * manip_weight + prof_with_clones.rankings[manip_weight:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, classification=False, layers=[128, 64, 32]):\n",
    "        super().__init__()\n",
    "\n",
    "        self.output_dim = math.factorial(output_dim)  # action space is [0, (output_dim)! - 1]\n",
    "\n",
    "        module_list = []\n",
    "\n",
    "        layers = [input_dim] + layers + [self.output_dim]\n",
    "\n",
    "        for i in range(1, len(layers)):\n",
    "            module_list.append(\n",
    "                nn.Linear(layers[i - 1], layers[i]),\n",
    "            )\n",
    "            if i != len(layers) - 1:\n",
    "                module_list.append(\n",
    "                    nn.LeakyReLU(),\n",
    "                )\n",
    "\n",
    "        if classification:\n",
    "            module_list.append(\n",
    "                nn.Sigmoid(),\n",
    "            )\n",
    "        else:\n",
    "            module_list.append(\n",
    "                nn.Softmax(dim=-1),\n",
    "            )\n",
    "\n",
    "        self.model = nn.Sequential(*module_list)\n",
    "\n",
    "        print(self.model)\n",
    "\n",
    "\n",
    "    def forward(self, manipulator_utilities, additional_contexts): # returns (action_probs, action) # try borda/plurality scores\n",
    "        # context = [bs, n_c] (utility of voter 0)\n",
    "        # plurality_scores = [bs, n_c]\n",
    "\n",
    "        context = torch.cat([manipulator_utilities, additional_contexts], dim=-1)\n",
    "\n",
    "        action_probs = self.model(context)\n",
    "\n",
    "        dist=torch.distributions.categorical.Categorical(probs=action_probs)\n",
    "        actions = dist.sample()\n",
    "\n",
    "        # action_probs: [BS, num_possible_actions]\n",
    "        # actions: [BS,]\n",
    "        return action_probs, actions\n",
    "\n",
    "cross_entropy_loss = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_score_context(profs, scoring_rule = 'plurality', device=DEVICE):\n",
    "\n",
    "    if scoring_rule == 'plurality':\n",
    "        scores = [ prof.plurality_scores() for prof in profs] # list of dicts\n",
    "    elif scoring_rule == 'borda':\n",
    "        scores = [ prof.borda_scores() for prof in profs] # list of dicts\n",
    "\n",
    "    final_scores = []\n",
    "    for score in scores:\n",
    "\n",
    "        scores_list = []\n",
    "        for cand_index in sorted(score.keys()):\n",
    "            scores_list.append(score[cand_index])\n",
    "\n",
    "        final_scores.append(scores_list)\n",
    "\n",
    "    return torch.tensor(\n",
    "        final_scores,\n",
    "        device=device,\n",
    "    ) # [bs, n_c]\n",
    "\n",
    "\n",
    "def generate_majority_contexts(profs, num_cands, device=DEVICE):\n",
    "    # generates margin contexts\n",
    "\n",
    "    # profs: list of profiles\n",
    "    # outputs: [bs, num_cands * num_cands]\n",
    "\n",
    "    bs = len(profs)\n",
    "    \n",
    "    contexts = torch.zeros((bs, num_cands, num_cands), device=device)\n",
    "    \n",
    "    for pidx, prof in enumerate(profs): \n",
    "        for c1 in prof.candidates: \n",
    "            for c2 in prof.candidates: \n",
    "                if prof.majority_prefers(c1, c2):\n",
    "                    contexts[pidx, c1, c2] = 1.0\n",
    "                elif prof.majority_prefers(c2, c1): \n",
    "                    contexts[pidx, c1, c2] = -1.0\n",
    "                else:\n",
    "                    contexts[pidx, c1, c2] = 0.0\n",
    "\n",
    "    contexts = torch.flatten(contexts, start_dim=1) # [bs, num_cands * num_cands]\n",
    "    return contexts\n",
    "\n",
    "\n",
    "def generate_sincere_winners_contexts(profs, num_cands, vm, device=DEVICE):\n",
    "\n",
    "    bs = len(profs)\n",
    "\n",
    "    contexts = torch.zeros((bs, num_cands), device=device)\n",
    "\n",
    "    for pidx, prof in enumerate(profs):\n",
    "        ws = vm(prof)\n",
    "        for c in ws:\n",
    "            contexts[pidx, c] = 1.0\n",
    "\n",
    "    return contexts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_function(\n",
    "    actions, \n",
    "    utility_fns, \n",
    "    profs, \n",
    "    vm, \n",
    "    num_cands, \n",
    "    manip_weight, \n",
    "    metric_op='normalized_subtract'\n",
    "    ):\n",
    "    # actions = [BS,]\n",
    "    # uprofs = list of uprofs\n",
    "    # vm = voting method fn\n",
    "\n",
    "    profs_with_clones = [clone_voter(prof, manip_weight=manip_weight) for prof in profs]\n",
    "\n",
    "    ws_batch = [vm(prof) for prof in profs_with_clones]\n",
    "    cands_batch = [prof.candidates for prof in profs_with_clones]\n",
    "\n",
    "    exp_util_ws_batch = torch.tensor([\n",
    "        np.average([utility_fn(w) for w in ws])\n",
    "        for utility_fn, ws in zip(utility_fns, ws_batch)\n",
    "    ]).float() # [BS,]\n",
    "    exp_util_ws_batch = exp_util_ws_batch.to(DEVICE)\n",
    "\n",
    "    max_util_batch = torch.tensor([\n",
    "        np.max([utility_fn(c) for c in cands])\n",
    "        for utility_fn, cands in zip(utility_fns, cands_batch)\n",
    "    ]).float() # [BS,]\n",
    "    max_util_batch = max_util_batch.to(DEVICE)\n",
    "\n",
    "    min_util_batch = torch.tensor([\n",
    "        np.min([utility_fn(c) for c in cands])\n",
    "        for utility_fn, cands in zip(utility_fns, cands_batch)\n",
    "    ]).float() # [BS,]\n",
    "    min_util_batch = min_util_batch.to(DEVICE)\n",
    "\n",
    "    new_profs = [\n",
    "        apply_manipulation(prof, permutations_of[num_cands][action], manip_weight)\n",
    "        for prof, action in zip(profs_with_clones, actions)\n",
    "    ]\n",
    "\n",
    "    new_ws_batch = [vm(new_prof) for new_prof in new_profs]\n",
    "    \n",
    "    new_exp_util_ws_batch = torch.tensor([\n",
    "        np.average([utility_fn(w) for w in new_ws])\n",
    "        for utility_fn, new_ws in zip(utility_fns, new_ws_batch)\n",
    "    ]).float() # [BS,]\n",
    "\n",
    "    new_exp_util_ws_batch = new_exp_util_ws_batch.to(DEVICE)\n",
    "\n",
    "    if metric_op == 'subtract':\n",
    "        reward = new_exp_util_ws_batch - exp_util_ws_batch\n",
    "    elif metric_op == 'divide':\n",
    "        reward = new_exp_util_ws_batch / exp_util_ws_batch\n",
    "    elif metric_op == 'normalized_subtract':\n",
    "        reward = (new_exp_util_ws_batch - exp_util_ws_batch) / (max_util_batch - min_util_batch)\n",
    "\n",
    "    return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_profits_actions(\n",
    "    agent, \n",
    "    batch_size, \n",
    "    vm, \n",
    "    num_cands, \n",
    "    num_voters, \n",
    "    manip_weight, \n",
    "    elections, \n",
    "    decision_rule='argmax', \n",
    "    metric_op=\"normalized_subtract\", \n",
    "    agent_infos=('plurality_scores',)):\n",
    "\n",
    "    manipulator_utility_fns, profiles = elections\n",
    "\n",
    "    manipulator_utilities = torch.tensor(\n",
    "        [\n",
    "            [m_util_fn(i) for i in range(num_cands)]\n",
    "            for m_util_fn in manipulator_utility_fns\n",
    "        ],\n",
    "    ).float().to(DEVICE)\n",
    "\n",
    "    additional_contexts = None # guarantee that this is of shape [bs, x]\n",
    "\n",
    "    additional_contexts = [] # guarantee that each entry is of shape [bs, x]\n",
    "\n",
    "    for agent_info in agent_infos:\n",
    "        additional_context = None\n",
    "\n",
    "        if agent_info == 'full':\n",
    "            additional_context = generate_full_knowledge_contexts(\n",
    "                profiles,\n",
    "                num_cands=num_cands,\n",
    "                num_voters=num_voters,\n",
    "                device=DEVICE\n",
    "            )\n",
    "\n",
    "        elif agent_info == 'anon_prof':\n",
    "            additional_context = generate_anon_prof_contexts(\n",
    "                profiles,\n",
    "                num_cands=num_cands,\n",
    "                device=DEVICE,\n",
    "            )\n",
    "\n",
    "        elif agent_info == 'plurality_scores':\n",
    "\n",
    "            additional_context = generate_score_context(\n",
    "                profiles,\n",
    "                scoring_rule='plurality',\n",
    "                device=DEVICE,\n",
    "            ).float()\n",
    "            \n",
    "        elif agent_info == 'plurality_ranking':\n",
    "\n",
    "            additional_context = generate_score_ranking_context(\n",
    "                profiles,\n",
    "                scoring_rule='plurality',\n",
    "                device=DEVICE,\n",
    "            ).float()\n",
    "            \n",
    "        elif agent_info == 'borda_scores':\n",
    "            additional_context = generate_score_context(\n",
    "                profiles,\n",
    "                scoring_rule='borda',\n",
    "                device=DEVICE,\n",
    "            ).float()\n",
    "\n",
    "        elif agent_info == 'margin':\n",
    "            additional_context = generate_margin_contexts(\n",
    "                profiles,\n",
    "                num_cands=num_cands,\n",
    "                device=DEVICE\n",
    "            )\n",
    "        elif agent_info == 'qual_margin':\n",
    "            additional_context = generate_qual_margin_contexts(\n",
    "                profiles,\n",
    "                num_cands=num_cands,\n",
    "                device=DEVICE\n",
    "            )\n",
    "\n",
    "        elif agent_info == 'majority':\n",
    "            additional_context = generate_majority_contexts(\n",
    "                profiles,\n",
    "                num_cands=num_cands,\n",
    "                device=DEVICE\n",
    "            )\n",
    "\n",
    "\n",
    "        elif agent_info == 'sincere_winners':\n",
    "            additional_context = generate_sincere_winners_contexts(\n",
    "                profiles,\n",
    "                num_cands=num_cands,\n",
    "                vm=vm,\n",
    "                device=DEVICE\n",
    "            )\n",
    "            \n",
    "        additional_contexts.append(additional_context)\n",
    "\n",
    "    additional_contexts = torch.cat(additional_contexts, dim=-1)\n",
    "\n",
    "    action_probs_batch, actions_batch = agent(manipulator_utilities, additional_contexts)\n",
    "\n",
    "    if decision_rule == 'expectation':\n",
    "\n",
    "        eval_result = torch.zeros((batch_size,)).to(DEVICE)\n",
    "\n",
    "        for i in range(action_probs_batch.shape[-1]):\n",
    "            actions_batch = torch.ones_like(actions_batch) * i\n",
    "\n",
    "            reward_val = reward_function(\n",
    "                actions=actions_batch,\n",
    "                utility_fns=manipulator_utility_fns,\n",
    "                profs=profiles,\n",
    "                vm=vm,\n",
    "                num_cands=num_cands,\n",
    "                manip_weight=manip_weight,\n",
    "                metric_op=metric_op,\n",
    "            )\n",
    "\n",
    "            eval_result += reward_val * action_probs_batch[:, i]\n",
    "    elif decision_rule == 'argmax':\n",
    "        # using the argmax\n",
    "        actions_batch = torch.argmax(action_probs_batch, dim=-1)\n",
    "        eval_result = reward_function(\n",
    "                actions=actions_batch,\n",
    "                utility_fns=manipulator_utility_fns,\n",
    "                profs=profiles,\n",
    "                vm=vm,\n",
    "                num_cands=num_cands,\n",
    "                manip_weight=manip_weight,\n",
    "                metric_op=metric_op,\n",
    "            )\n",
    "    elif decision_rule == 'distribution':\n",
    "        eval_result = reward_function(\n",
    "            actions=actions_batch,\n",
    "            utility_fns=manipulator_utility_fns,\n",
    "            profs=profiles,\n",
    "            vm=vm,\n",
    "            num_cands=num_cands,\n",
    "            manip_weight=manip_weight,\n",
    "            metric_op=metric_op,\n",
    "        )\n",
    "    else:\n",
    "        raise Exception(\"pick one\")\n",
    "    \n",
    "    return eval_result, actions_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_utility_profile(\n",
    "        num_cands, \n",
    "        num_voters, \n",
    "        probmodel = 'uniform', \n",
    "        num_profiles = 1\n",
    "        ): \n",
    "\n",
    "    if probmodel == 'uniform': \n",
    "        return pref_voting.generate_utility_profiles.generate_utility_profile_uniform(num_cands, num_voters, num_profiles = num_profiles)\n",
    "    \n",
    "    elif probmodel == 'spatial_2dim':\n",
    "        ndims = 2\n",
    "        sprofs = pref_voting.generate_spatial_profiles.generate_spatial_profile(num_cands, num_voters, ndims, num_profiles = num_profiles)\n",
    "        return [sprof.to_utility_profile() for sprof in sprofs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_agent(\n",
    "    model_size,\n",
    "    num_cands, \n",
    "    num_voters, \n",
    "    agent_infos, \n",
    "    vm, \n",
    "    probmodel='uniform', \n",
    "    labeling='satisfice', \n",
    "    gen=1,\n",
    "    manip_weight=1\n",
    "    ):\n",
    "    # Get the trained model for the provided parameters\n",
    "\n",
    "    agents = None\n",
    "\n",
    "    # load the appropriate models dictionary\n",
    "    for file in glob.glob(f\"example_trained_models/Borda_1_6_10_uniform_('majority',)_1_08-18-2023_09-10-18.pickle\"):\n",
    "        print(f\"Loading: {file}\")\n",
    "        agents = pickle.load(open(file, \"rb\"))\n",
    "\n",
    "    if agents is None: \n",
    "        print(f\"ERROR: models file not found:\", f\"models/models_{agent_infos}_{probmodel}_{labeling}_{manip_weight}/{vm.name}_{gen}_{num_cands}_{num_voters}_{probmodel}_{agent_infos}_{manip_weight}_*.pickle\")\n",
    "        return None\n",
    "\n",
    "    # find the agent with the key[2] (the model_size) equal to the model_size\n",
    "    for key in agents.keys(): \n",
    "        if key[2] == model_size:\n",
    "            agent = agents[key][0].to(DEVICE)\n",
    "            losses = agents[key][1]\n",
    "\n",
    "    # plot the losses for the model\n",
    "    plt.plot(losses)\n",
    "    plt.title(f\"model size {model_size} for {vm.name} losses\")\n",
    "    plt.show();\n",
    "    \n",
    "    return agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
